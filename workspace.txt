📦 fct_scraper_backend/
│
├── app.py                    → Punto de entrada principal para la API FastAPI
├── celery_app.py             → Inicializa Celery y conecta con Redis
├── docker-compose.yml        → Orquesta servicios: API + Celery + Redis
├── Dockerfile                → Define la imagen Docker del backend
├── requirements.txt          → Lista de dependencias del proyecto
├── README.md                 → Documentación general del sistema
│
├── state_instagram.json      → Estado de sesión Playwright para Instagram
├── state_tiktok.json         → Estado de sesión Playwright para TikTok
├── state_facebook.json       → Estado de sesión Playwright para Facebook
├── state_youtube.json        → Estado de sesión Playwright para YouTube
├── state_x.json              → Estado de sesión Playwright para X (Twitter)
│
├── tests/                    → Carpeta de tests (vacía o en desarrollo)
│   └──
│
├── decorators/               → Decoradores reutilizables
│   ├── __init__.py
│   └── historial.py          → Decorador para registrar búsquedas
│
├── exports/                  → Generación de archivos CSV/Excel
│   ├── __init__.py
│   └── exporter.py           → Lógica para exportar los resultados scrapeados
│
├── scraping/                 → Scrapers por plataforma
│   ├── __init__.py
│   ├── facebook/
│   │   ├── __init__.py
│   │   └── perfil.py
│   ├── telegram/
│   │   ├── __init__.py
│   │   └── canal.py
│   ├── tiktok/
│   │   ├── __init__.py
│   │   ├── perfil.py
│   │   ├── seguidos.py
│   │   └── seguidores.py
│   ├── web/
│   │   ├── __init__.py
│   │   └── web_scraper.py    → (Desactivado) Scraping de resultados web (StartPage/Bing)
│   ├── x/
│   │   ├── __init__.py
│   │   └── perfil.py
│   ├── youtube/
│   │   ├── __init__.py
│   │   └── canal.py
│   └── instagram/
│       ├── __init__.py
│       ├── perfil.py
│       ├── seguidores.py
│       └── seguidos.py
│
├── utils/                    → Funciones de apoyo general
│   ├── __init__.py
│   ├── flujo_scraping.py     → Orquesta scraping multired (perfil + fallback)
│   ├── exportador_perfil.py  → Ejecuta scraping de perfil y exporta automáticamente al backend
│   ├── busqueda_cruzada.py   → (Desactivado) Scraping web si no hay resultados directos
│   ├── busqueda_username.py  → (Desactivado) Scraping de username entre redes
│   ├── history.py            → Guarda y recupera historial de scraping
│   ├── normalizador.py       → Limpia y estandariza resultados
│   └── validator.py          → Validación de emails y teléfonos
│
├── routes/                   → Rutas de FastAPI por plataforma
│   ├── __init__.py
│   ├── web.py
│   ├── instagram.py
│   ├── youtube.py
│   ├── facebook.py
│   ├── x.py
│   ├── tiktok.py
│   ├── telegram.py
│   └── resultados.py         → Devuelve resultado de tareas Celery / controla historial y exportaciones
│
├── static/                   → Archivos frontend (interfaz HTML)
│   ├── css/
│   │   └── style.css         → Estilos personalizados
│   ├── js/
│   │   └── main.js           → Toda la lógica del frontend JS (unificada)
│   └── index.html            → Página web principal
│
├── tasks/                    → Tareas Celery para scraping intensivo
│   ├── __init__.py
│   ├── celery_worker.py      → Arranca el worker de tareas
│   ├── instagram.py          → Tareas: seguidores / seguidos
│   ├── tiktok.py             → Tareas: seguidores / seguidos
│   └── x.py                  → Tareas: tweets
│
├── services/                 → Infraestructura: proxies, navegador, logs
│   ├── __init__.py
│   ├── proxy_loader.py       → Convierte raw_proxies.txt → proxies.json
│   ├── proxy_checker.py      → Verifica qué proxies funcionan
│   ├── proxy_pool.py         → Gestiona pool: da uno válido, reporta bloqueos
│   ├── proxy_format.py       → Adapta proxy para requests o Playwright
│   ├── playwright_tools.py   → Inicia navegador con proxy, user-agent, contexto
│   ├── raw_proxies.txt       → Proxies en bruto (copiados manualmente)
│   ├── proxies.json          → Proxies válidos listos para usar
│   ├── logging_config.py     → Formato, nivel y estilo de logs estructurados
│   ├── user_agents.py        → Lista de user agents aleatorios
│   └── proxy_scraper.py      → ❌ Inutilizado (raspador de proxies gratuitos)
